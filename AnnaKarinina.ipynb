{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"anna.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "    \n",
    "vocab = sorted(set(text))\n",
    "vocab_encode = {v:i for i,v in enumerate(vocab)}\n",
    "vocab_decode = {i:v for v,i in vocab_encode.items()}\n",
    "encoded = np.array([vocab_encode[c] for c in text], dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 8\n",
    "sequence_length = 128\n",
    "lstm_feature_depth = 256\n",
    "lstm_layer_depth = 2\n",
    "num_classes = len(vocab)\n",
    "\n",
    "save_interval = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverythin'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31, 64, 57, 72, 76, 61, 74,  1, 16,  0,  0,  0, 36, 57, 72, 72, 81,\n",
       "        1, 62, 57, 69, 65, 68, 65, 61, 75,  1, 57, 74, 61,  1, 57, 68, 68,\n",
       "        1, 57, 68, 65, 67, 61, 26,  1, 61, 78, 61, 74, 81,  1, 77, 70, 64,\n",
       "       57, 72, 72, 81,  1, 62, 57, 69, 65, 68, 81,  1, 65, 75,  1, 77, 70,\n",
       "       64, 57, 72, 72, 81,  1, 65, 70,  1, 65, 76, 75,  1, 71, 79, 70,  0,\n",
       "       79, 57, 81, 13,  0,  0, 33, 78, 61, 74, 81, 76, 64, 65, 70], dtype=int16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batches : 1938\n"
     ]
    }
   ],
   "source": [
    "target = np.roll(encoded, -1)\n",
    "target[-1] = 0\n",
    "\n",
    "chars_per_batch = train_batch_size * sequence_length\n",
    "num_batches = len(encoded)//chars_per_batch\n",
    "print(\"number of batches : {}\".format(num_batches))\n",
    "\n",
    "# discard extra characters\n",
    "encoded = encoded[:num_batches*chars_per_batch]\n",
    "target = target[:num_batches*chars_per_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_sequences, target_batch_sequences, idx, sequence_length):\n",
    "    batch = batch_sequences[:,idx*sequence_length:(idx+1)*sequence_length]\n",
    "    target_batch = target_batch_sequences[:,idx*sequence_length:(idx+1)*sequence_length]\n",
    "    return batch, target_batch\n",
    "\n",
    "batch_sequences = encoded.reshape((train_batch_size, -1))\n",
    "target_batch_sequences = target.reshape((train_batch_size, -1))\n",
    "\n",
    "#batch, target_batch = get_batch(batch_sequences, target_batch_sequences, 0, sequence_length)\n",
    "batch, target_batch = get_batch(batch_sequences, target_batch_sequences, 0, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[31, 64, 57, 72, 76, 61, 74,  1, 16,  0,  0,  0, 36, 57, 72, 72, 81,\n",
       "          1, 62, 57, 69, 65, 68, 65, 61, 75,  1, 57, 74, 61,  1, 57],\n",
       "        [ 1, 77, 72, 71, 70,  1, 64, 61, 74, 13,  0,  0, 29, 76,  1, 44, 61,\n",
       "         76, 61, 74, 75, 58, 77, 74, 63, 11,  1, 57, 75,  1, 75, 71],\n",
       "        [57, 76, 64, 61, 74,  1, 58, 61, 62, 71, 74, 61, 11,  1, 57, 70, 60,\n",
       "          1, 70, 71, 79, 11,  1, 61, 78, 61, 74,  1, 75, 65, 70, 59],\n",
       "        [79, 57, 81,  0, 79, 64, 65, 68, 61,  1, 37,  7, 69,  1, 65, 70,  1,\n",
       "         76, 64, 61,  1, 75, 61, 74, 78, 65, 59, 61, 27,  1, 37, 62],\n",
       "        [11,  1, 64, 57, 70, 60, 61, 60,  1, 64, 61, 74,  1, 64, 65, 75,  1,\n",
       "         60, 65, 57, 74, 81, 13,  1, 36, 61,  1, 67, 70, 61, 79,  1],\n",
       "        [68, 61, 80, 61, 81,  1, 29, 68, 61, 80, 57, 70, 60, 74, 71, 78, 65,\n",
       "         76, 59, 64,  1, 68, 65, 75, 76, 61, 70, 61, 60,  1, 76, 71],\n",
       "        [60, 11,  1, 79, 64, 65, 59, 64,  1, 76, 64, 61,  1, 64, 71, 74, 75,\n",
       "         61,  1, 64, 57, 60,  1, 69, 57, 60, 61,  1, 79, 61, 76,  1],\n",
       "        [75, 11,  1, 58, 77, 76,  1, 75, 76, 65, 68, 68,  1, 76, 64, 61,  1,\n",
       "         72, 74, 65, 70, 59, 65, 72, 68, 61,  1, 71, 62,  1, 71, 77]], dtype=int16),\n",
       " array([[64, 57, 72, 76, 61, 74,  1, 16,  0,  0,  0, 36, 57, 72, 72, 81,  1,\n",
       "         62, 57, 69, 65, 68, 65, 61, 75,  1, 57, 74, 61,  1, 57, 68],\n",
       "        [77, 72, 71, 70,  1, 64, 61, 74, 13,  0,  0, 29, 76,  1, 44, 61, 76,\n",
       "         61, 74, 75, 58, 77, 74, 63, 11,  1, 57, 75,  1, 75, 71, 71],\n",
       "        [76, 64, 61, 74,  1, 58, 61, 62, 71, 74, 61, 11,  1, 57, 70, 60,  1,\n",
       "         70, 71, 79, 11,  1, 61, 78, 61, 74,  1, 75, 65, 70, 59, 61],\n",
       "        [57, 81,  0, 79, 64, 65, 68, 61,  1, 37,  7, 69,  1, 65, 70,  1, 76,\n",
       "         64, 61,  1, 75, 61, 74, 78, 65, 59, 61, 27,  1, 37, 62,  1],\n",
       "        [ 1, 64, 57, 70, 60, 61, 60,  1, 64, 61, 74,  1, 64, 65, 75,  1, 60,\n",
       "         65, 57, 74, 81, 13,  1, 36, 61,  1, 67, 70, 61, 79,  1, 76],\n",
       "        [61, 80, 61, 81,  1, 29, 68, 61, 80, 57, 70, 60, 74, 71, 78, 65, 76,\n",
       "         59, 64,  1, 68, 65, 75, 76, 61, 70, 61, 60,  1, 76, 71,  1],\n",
       "        [11,  1, 79, 64, 65, 59, 64,  1, 76, 64, 61,  1, 64, 71, 74, 75, 61,\n",
       "          1, 64, 57, 60,  1, 69, 57, 60, 61,  1, 79, 61, 76,  1, 65],\n",
       "        [11,  1, 58, 77, 76,  1, 75, 76, 65, 68, 68,  1, 76, 64, 61,  1, 72,\n",
       "         74, 65, 70, 59, 65, 72, 68, 61,  1, 71, 62,  1, 71, 77, 74]], dtype=int16))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(predictions):\n",
    "    dec = [[vocab_decode[i] for i in row] for row in predictions]\n",
    "    return [''.join(list) for list in dec]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.int32, [None, None], name=\"inputs\")\n",
    "y = tf.placeholder(tf.int32, [None, None], name=\"outputs\")\n",
    "\n",
    "dropout = tf.placeholder(tf.float32, name=\"dropout\")\n",
    "batch_size = tf.placeholder(tf.int32, [], name=\"batch_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cell(lstm_feature_depth, dropout):\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(lstm_feature_depth, activation=tf.nn.tanh)\n",
    "    lstm_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_cell, output_keep_prob=1-dropout)\n",
    "    return lstm_cell\n",
    "\n",
    "multirnn_cell = tf.nn.rnn_cell.MultiRNNCell([create_cell(lstm_feature_depth, dropout) for _ in range(lstm_layer_depth)])\n",
    "initial_state = multirnn_cell.zero_state(batch_size=batch_size, dtype=tf.float32)\n",
    "rnn_out, new_state = tf.nn.dynamic_rnn(cell=multirnn_cell, inputs=tf.one_hot(x, num_classes), initial_state=initial_state)\n",
    "logits = tf.layers.dense(inputs=rnn_out, units=num_classes)\n",
    "softmax = tf.nn.softmax(logits)\n",
    "\n",
    "predictions = tf.argmax(input=softmax, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training graph\n",
    "y_one_hot = tf.one_hot(y, num_classes)\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_one_hot)\n",
    "loss = tf.reduce_mean(loss)\n",
    "\n",
    "tvars = tf.trainable_variables()\n",
    "grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), 5)\n",
    "optimize = tf.train.AdamOptimizer(learning_rate=0.001).apply_gradients(zip(grads, tvars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 3.6990115642547607\n",
      "Loss : 3.507460117340088\n",
      "Loss : 3.347991943359375\n",
      "Loss : 3.2357261180877686\n",
      "Loss : 3.166090488433838\n",
      "Loss : 3.1533255577087402\n",
      "Loss : 3.154907464981079\n",
      "Loss : 3.139657735824585\n",
      "Loss : 3.140908718109131\n",
      "Loss : 3.2264699935913086\n",
      "Loss : 3.2220911979675293\n",
      "Loss : 3.1838788986206055\n",
      "Loss : 3.191047191619873\n",
      "Loss : 3.2038235664367676\n",
      "Loss : 3.2396669387817383\n",
      "Loss : 3.2552709579467773\n",
      "Loss : 3.1707069873809814\n",
      "Loss : 3.221566677093506\n",
      "Loss : 3.2221131324768066\n",
      "Loss : 3.145331621170044\n",
      "Loss : 3.1663479804992676\n",
      "Loss : 3.1408705711364746\n",
      "Loss : 3.079702854156494\n",
      "Loss : 3.0622129440307617\n",
      "Loss : 3.110764980316162\n",
      "Loss : 3.134237289428711\n",
      "Loss : 3.0624570846557617\n",
      "Loss : 3.0594770908355713\n",
      "Loss : 3.1090526580810547\n",
      "Loss : 3.027599811553955\n",
      "Loss : 3.0185232162475586\n",
      "Loss : 3.040438413619995\n",
      "Loss : 3.080812454223633\n",
      "Loss : 2.9908738136291504\n",
      "Loss : 2.9409680366516113\n",
      "Loss : 3.020944595336914\n",
      "Loss : 2.849097967147827\n",
      "Loss : 2.9092535972595215\n",
      "Loss : 2.889892101287842\n",
      "Loss : 2.9188027381896973\n",
      "Loss : 2.782512664794922\n",
      "Loss : 2.837691307067871\n",
      "Loss : 2.889688491821289\n",
      "Loss : 2.7412033081054688\n",
      "Loss : 2.7311153411865234\n",
      "Loss : 2.746528148651123\n",
      "Loss : 2.6864566802978516\n",
      "Loss : 2.67294979095459\n",
      "Loss : 2.53044056892395\n",
      "Loss : 2.607710361480713\n",
      "Loss : 2.555758237838745\n",
      "Loss : 2.66776704788208\n",
      "Loss : 2.680213451385498\n",
      "Loss : 2.6048426628112793\n",
      "Loss : 2.625305414199829\n",
      "Loss : 2.5934019088745117\n",
      "Loss : 2.5255277156829834\n",
      "Loss : 2.5444092750549316\n",
      "Loss : 2.5454628467559814\n",
      "Loss : 2.6184232234954834\n",
      "Loss : 2.4859230518341064\n",
      "Loss : 2.5287938117980957\n",
      "Loss : 2.579956531524658\n",
      "Loss : 2.5387144088745117\n",
      "Loss : 2.510524272918701\n",
      "Loss : 2.54026460647583\n",
      "Loss : 2.511000394821167\n",
      "Loss : 2.492081880569458\n",
      "Loss : 2.352442979812622\n",
      "Loss : 2.504668951034546\n",
      "Loss : 2.4899039268493652\n",
      "Loss : 2.4154505729675293\n",
      "Loss : 2.4501404762268066\n",
      "Loss : 2.4108855724334717\n",
      "Loss : 2.4898056983947754\n",
      "Loss : 2.4116063117980957\n",
      "Loss : 2.4962472915649414\n",
      "Loss : 2.422360897064209\n",
      "Loss : 2.47098970413208\n",
      "Loss : 2.377307891845703\n",
      "Loss : 2.344972610473633\n",
      "Loss : 2.436819314956665\n",
      "Loss : 2.427945375442505\n",
      "Loss : 2.4449715614318848\n",
      "Loss : 2.391580581665039\n",
      "Loss : 2.27899432182312\n",
      "Loss : 2.4101486206054688\n",
      "Loss : 2.411661386489868\n",
      "Loss : 2.3623571395874023\n",
      "Loss : 2.368464708328247\n",
      "Loss : 2.337674617767334\n",
      "Loss : 2.367555856704712\n",
      "Loss : 2.4842734336853027\n",
      "Loss : 2.2521209716796875\n",
      "Loss : 2.3072597980499268\n",
      "Loss : 2.358182191848755\n",
      "Loss : 2.361793041229248\n",
      "Loss : 2.3989362716674805\n",
      "Loss : 2.309536933898926\n",
      "Loss : 2.3158316612243652\n",
      "Loss : 2.2821927070617676\n",
      "Loss : 2.284350872039795\n",
      "Loss : 2.334031343460083\n",
      "Loss : 2.2439751625061035\n",
      "Loss : 2.2873950004577637\n",
      "Loss : 2.2331044673919678\n",
      "Loss : 2.3100333213806152\n",
      "Loss : 2.3440892696380615\n",
      "Loss : 2.338992118835449\n",
      "Loss : 2.3157334327697754\n",
      "Loss : 2.246783971786499\n",
      "Loss : 2.210230827331543\n",
      "Loss : 2.2389938831329346\n",
      "Loss : 2.2420475482940674\n",
      "Loss : 2.3142318725585938\n",
      "Loss : 2.1501176357269287\n",
      "Loss : 2.1872878074645996\n",
      "Loss : 2.3192601203918457\n",
      "Loss : 2.187145471572876\n",
      "Loss : 2.3019614219665527\n",
      "Loss : 2.3906121253967285\n",
      "Loss : 2.264529228210449\n",
      "Loss : 2.164215564727783\n",
      "Loss : 2.261342763900757\n",
      "Loss : 2.2879233360290527\n",
      "Loss : 2.3541059494018555\n",
      "Loss : 2.2552785873413086\n",
      "Loss : 2.2170815467834473\n",
      "Loss : 2.261042356491089\n",
      "Loss : 2.224318742752075\n",
      "Loss : 2.158543109893799\n",
      "Loss : 2.1850149631500244\n",
      "Loss : 2.267273426055908\n",
      "Loss : 2.289916753768921\n",
      "Loss : 2.151404857635498\n",
      "Loss : 2.1706748008728027\n",
      "Loss : 2.2004876136779785\n",
      "Loss : 2.2050068378448486\n",
      "Loss : 2.0949654579162598\n",
      "Loss : 2.214780330657959\n",
      "Loss : 2.164489269256592\n",
      "Loss : 2.2597036361694336\n",
      "Loss : 2.1754112243652344\n",
      "Loss : 2.2192275524139404\n",
      "Loss : 2.1786978244781494\n",
      "Loss : 2.2168097496032715\n",
      "Loss : 2.123765468597412\n",
      "Loss : 2.2182159423828125\n",
      "Loss : 2.326782703399658\n",
      "Loss : 2.088778495788574\n",
      "Loss : 2.2006335258483887\n",
      "Loss : 2.106480598449707\n",
      "Loss : 2.230431318283081\n",
      "Loss : 2.111077308654785\n",
      "Loss : 2.033460855484009\n",
      "Loss : 2.0439720153808594\n",
      "Loss : 2.1021997928619385\n",
      "Loss : 2.080956220626831\n",
      "Loss : 2.2694826126098633\n",
      "Loss : 2.157487392425537\n",
      "Loss : 2.1628711223602295\n",
      "Loss : 2.1006171703338623\n",
      "Loss : 1.9890291690826416\n",
      "Loss : 2.1544029712677\n",
      "Loss : 2.1771483421325684\n",
      "Loss : 2.0846774578094482\n",
      "Loss : 2.1025283336639404\n",
      "Loss : 2.06526517868042\n",
      "Loss : 2.076658248901367\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-28da5bfcb28f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         }\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_start_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0msave_interval\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=10)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batch_start_state = sess.run(initial_state, feed_dict={batch_size:train_batch_size})\n",
    "    \n",
    "    counter=0\n",
    "    for t in range(num_batches):\n",
    "        x_batch, y_batch = get_batch(batch_sequences, target_batch_sequences, t, sequence_length)\n",
    "        feed = {\n",
    "            x:x_batch,\n",
    "            y:y_batch,\n",
    "            dropout:0.4,\n",
    "            batch_size:train_batch_size,\n",
    "            initial_state:batch_start_state\n",
    "        }\n",
    "\n",
    "        batch_loss, batch_start_state, _ = sess.run([loss, new_state, optimize], feed_dict=feed)\n",
    "        counter += 1\n",
    "        if(counter%save_interval==0):\n",
    "            print(\"Loss : {}\".format(batch_loss))\n",
    "            saver.save(sess, \"checkpoints/i{}.ckpt\".format(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest checkpoint : checkpoints/i845.ckpt\n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.train.latest_checkpoint('checkpoints')\n",
    "print(\"latest checkpoint : {}\".format(checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "test_seq, test_target = get_batch(np.expand_dims(encoded, axis=0), np.expand_dims(target, axis=0), 0, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/i845.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, save_path=checkpoint)\n",
    "    batch_start_state = sess.run(initial_state, feed_dict={batch_size:1})\n",
    "    feed = {x:test_seq, \n",
    "            y:test_target,\n",
    "            dropout:0,\n",
    "            batch_size:1,\n",
    "            initial_state:batch_start_state}\n",
    "    pred = sess.run(predictions, feed_dict=feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[31, 64, 57, 72, 76, 61, 74,  1, 16,  0,  0,  0, 36, 57, 72, 72, 81,\n",
       "          1, 62, 57, 69, 65, 68, 65, 61, 75,  1, 57, 74, 61,  1, 57, 68, 68,\n",
       "          1, 57, 68, 65, 67, 61, 26,  1, 61, 78, 61, 74, 81,  1, 77, 70, 64,\n",
       "         57, 72, 72, 81,  1, 62, 57, 69, 65, 68, 81,  1, 65, 75,  1, 77, 70,\n",
       "         64, 57, 72, 72, 81,  1, 65, 70,  1, 65, 76, 75,  1, 71, 79, 70,  0,\n",
       "         79, 57, 81, 13,  0,  0, 33, 78, 61, 74, 81, 76, 64, 65, 70, 63,  1,\n",
       "         79, 57, 75,  1, 65, 70,  1, 59, 71, 70, 62, 77, 75, 65, 71, 70,  1,\n",
       "         65, 70,  1, 76, 64, 61,  1, 43, 58, 68, 71, 70, 75, 67, 81, 75,  7,\n",
       "          1, 64, 71, 77, 75, 61, 13,  1, 48, 64, 61,  1, 79, 65, 62, 61,  1,\n",
       "         64, 57, 60,  0, 60, 65, 75, 59, 71, 78, 61, 74, 61, 60,  1, 76, 64,\n",
       "         57, 76,  1, 76, 64, 61,  1, 64, 77, 75, 58, 57, 70, 60,  1, 79, 57,\n",
       "         75,  1, 59, 57, 74, 74, 81, 65, 70, 63,  1, 71, 70,  1, 57, 70,  1,\n",
       "         65, 70, 76, 74, 65, 63, 77, 61,  1, 79, 65, 76, 64,  1, 57,  1, 34,\n",
       "         74, 61, 70, 59, 64,  0, 63, 65, 74, 68, 11,  1, 79, 64, 71,  1, 64,\n",
       "         57, 60,  1, 58, 61, 61, 70,  1, 57,  1, 63, 71, 78, 61, 74, 70, 61,\n",
       "         75]], dtype=int16),\n",
       " array([[71, 57, 65, 65, 65, 74,  1, 76, 71, 71, 62, 64, 61, 76,  1, 61,  1,\n",
       "         76, 71, 74,  1, 70, 61, 70, 60,  1, 57, 70,  1,  1, 76, 70, 68,  1,\n",
       "         76, 70, 68, 70, 61,  1,  1, 57, 70, 61, 74,  1,  1, 76, 70,  1, 61,\n",
       "         70, 61, 61,  1, 76, 71, 74,  1, 70, 61,  1, 57, 70,  1, 76, 70,  1,\n",
       "         61, 74, 61, 61,  1, 76, 70,  1, 76, 70,  1, 61, 71, 62,  1,  1, 76,\n",
       "         64, 75,  1,  1,  0,  3, 70, 61, 74, 61,  1, 64, 61, 70, 63,  1, 76,\n",
       "         64, 75,  1, 76, 70,  1, 76, 71, 69, 60, 61, 74, 76, 70, 70,  1, 76,\n",
       "         70,  1, 76, 64, 61,  1, 75, 70, 68, 61, 70, 63,  1, 81,  1,  1, 75,\n",
       "         62, 61, 74, 68, 75, 60,  1, 48, 64, 61,  1, 75, 57, 75, 64,  1, 76,\n",
       "         61, 75,  1, 57, 71, 70, 76, 61, 74, 61, 60,  1, 60,  1, 57, 64, 61,\n",
       "         76,  1, 64, 64, 61,  1, 75, 57, 75,  1, 61, 70, 60,  1, 57, 64, 75,\n",
       "          1, 76, 71, 70, 61, 61,  1, 70, 63,  1, 76, 62,  1, 76, 70, 60, 76,\n",
       "         70,  1, 61, 61, 70, 61, 76, 60, 76, 57, 75, 64,  1, 64, 70, 72, 74,\n",
       "         71, 70, 75, 61,  1, 79, 71, 75, 61, 61,  1, 57, 64, 57,  1, 64, 57,\n",
       "         60,  1, 76, 61,  1, 74,  1, 76, 70, 76, 71, 74, 61,  1,  1, 61, 60,\n",
       "          1]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_seq, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256)\n",
      "oaiiir toofhet e tor nend an  tnl tnlne  aner  tn enee tor ne an tn eree tn tn eof  ths  \n",
      "\"nere heng ths tn tomdertnn tn the snleng y  sferlsd The sash tes aontered d ahet hhe sas end ahs tonee ng tf tndtn eenetdtash hnpronse wosee aha had te r tntore  ed \n"
     ]
    }
   ],
   "source": [
    "print(pred.shape)\n",
    "print(\"\\n-------------------------------------------------------------\\n\".join(decode(pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/i845.ckpt\n",
      "['e']\n",
      "['s']\n",
      "['r']\n",
      "['r']\n",
      "[' ']\n"
     ]
    }
   ],
   "source": [
    "prime = 'happy'\n",
    "gen = []\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, save_path=checkpoint)\n",
    "    char_start_state = sess.run(initial_state, feed_dict={batch_size:1})\n",
    "    \n",
    "    for p in prime:\n",
    "        feed = {\n",
    "            x:np.expand_dims(np.expand_dims(vocab_encode[p], axis=0), axis=0),\n",
    "            dropout:0,\n",
    "            batch_size:1,\n",
    "            initial_state:char_start_state\n",
    "        }\n",
    "        c, char_start_state = sess.run([predictions, new_state], feed_dict=feed)\n",
    "        print(decode(c))\n",
    "    \n",
    "    for i in range(128):\n",
    "        feed = {\n",
    "            x:c,\n",
    "            dropout:0,\n",
    "            batch_size:1,\n",
    "            initial_state:char_start_state\n",
    "        }\n",
    "        \n",
    "        c, char_start_state = sess.run([predictions, new_state], feed_dict=feed)\n",
    "        gen.append(c[0][0])\n",
    "gen = np.expand_dims(gen,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and the salle the salled and the salle the salled and the salle the salled and the salle the salled and the salle the salled and']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
